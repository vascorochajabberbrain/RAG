import time
from dotenv import load_dotenv
import os
import openai

# Load environment variables from .env file
load_dotenv()

_openaiclient = None

def get_openai_client():
    global _openaiclient
    if _openaiclient is None:  # Only initialize if not already created
        # to-do put this on the .env variable
        _openaiclient = openai.Client(api_key = os.getenv("OPENAI_API_KEY"))
    return _openaiclient

def clean_json_response(text):
    """Remove backticks and json tags from a GPT-typed json block."""
    text = text.strip()
    if text.startswith("```json"):
        text = text[len("```json"):].strip()
    if text.startswith("```"):
        text = text[len("```"):].strip()
    if text.endswith("```"):
        text = text[:-len("```")].strip()
    return text

def openai_chat_completion(prompt, text, model="gpt-4o"):
    """
    Function to get a chat completion from OpenAI's API.
    
    Args:
        prompt (str): The system prompt for the chat model.
        text (str): The user input text for the chat model.
    
    Returns:
        content: Content of the response generated by the model.
    """
    openai_client = get_openai_client()
    
    # Example prompt and text
    # prompt = "You are a helpful assistant that generates sentences based on the provided text."
    # text = "Your input text goes here."
    try:
        completion = openai_client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": prompt},
                    {"role": "user", "content": text}]
        )
    except openai.error.RateLimitError as e:
        # Extract details from the error object
        error_data = e.response.json()["error"]

        # Check if it's a token-per-minute (TPM) limit
        if "tokens per min" in error_data.get("message", "").lower():
            print("Hit the TPM (tokens per minute) limit. Will wait a bit and try again")
            time.sleep(10)  # Wait for 10 seconds before retrying
            completion = openai_client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": prompt},
                        {"role": "user", "content": text}]
            )
    #print(completion.choices[0].message.content)
    return completion.choices[0].message.content.strip()
