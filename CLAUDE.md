# CLAUDE.md — RAG Project Context (Jabberbrain)

> This file is read automatically at the start of every Claude Code session.
> Keep it updated as decisions are made. Last updated: 2026-02-25 (pipeline complete).

---

## Who We Are

**Jabberbrain** builds an advanced chatbot platform using a proprietary **Hierarchical Intent Recognition System (HIRS)**. LLMs are used tactically, not as the primary engine, to avoid hallucination and ensure responses are exactly as clients want.

---

## The Jabberbrain Chatbot Pipeline (simplified)

Each user input goes through this flow:

1. **Language selection** — User can pick a language from the chat UI. If not the solution's base language, input is translated to base language first. All processing happens in base language. Response is only translated back to the user's language at the very end.
2. **Simplification** — If input is long/complex, simplify it before processing.
3. **HIRS processing** — Input goes through our language engine → returns a triggered issue + other data.
4. **Content logic** — Decide if response comes from triggered issue or another issue → "Response issue".
5. **Response selection** — Select a response from the Response issue (based on conditions).
6. **Sentence analysis & scoring** — Split user input into "sentences" by type (greeting, in_scope, out_of_scope, etc.). Score each sentence against the selected Response text.
   - Good score → send response.
7. **Contextualization** — If bad score for in_scope sentences: look into earlier chat messages for missing context/data. Adjust sentence, re-process through HIRS. Score again.
   - Good score → send response.
8. **FAQ RAG fallback** — If still bad score: use LLM + FAQ text table to build a response.
9. **RAG scope check** — If user input "seems to" relate to a RAG scope:
   - Use HIRS as first filter (keywords/patterns) to detect if a specific RAG collection is a good candidate.
   - Also use the keyword/context metadata stored in the collection's JSON (generated by `workflow/suggest.py → suggest_collection_metadata`).
   - Multiple RAG collections can be used per solution (e.g. one for recipes, one for products).
   - Use LLM + retrieved RAG chunks to build response.
10. **AI-generated fallback** — If nothing: "Sorry I cannot help with X" or "Typically you should find X on our website…"

**Key design principle**: RAG is a fallback layer within the pipeline, not the primary engine.

---

## This Project: RAG Collection Builder

**Scope (now)**: Build and maintain RAG collections in Qdrant. Ingestion, chunking, embedding, storage, testing.

**Later**: Integration work across this RAG project and the Session Engine project (in a separate repo), either in Claude Code or Cursor or both.

---

## Architecture Overview

```
PDF / URL / TXT / CSV
        ↓
   [FETCH] raw text
        ↓
   [CLEAN] optional filters
        ↓
   [TRANSLATE_AND_CLEAN] optional (bilingual PDFs, e.g. PT+ES)
        ↓
   [CHUNK] → simple | hierarchical | proposition
        ↓
   [GROUP] optional semantic clustering
        ↓
   [PUSH_TO_QDRANT] embed + store
        ↓
User question → improve query → embed → similarity search → LLM → answer
```

### Vector DB
- **Qdrant** (local), 1536-dim vectors, cosine similarity
- **OpenAI text-embedding-ada-002** for embeddings
- **GPT-4o-mini** for chunking, group descriptions, query rewriting
- **GPT-4o** for final answer generation

### Collection Types
| Type | Description |
|------|-------------|
| `scs` | Self-Contained Sentences — individual atomic facts |
| `group` | Groups of SCSs with LLM-generated descriptions (semantic clustering) |
| `group_sameSource` | Groups organized by source file |

### Chunking Modes
| Mode | Speed | Cost | Best For |
|------|-------|------|----------|
| Simple | Fast | Free | Quick tests |
| Hierarchical | Medium | Free | Production default — parent context + child passages |
| Proposition | Slow | $ | Highest quality — LLM decomposes into atomic facts |

---

## Key Files & Folders

| File/Folder | Purpose |
|-------------|---------|
| `workflow/models.py` | `WorkflowState` dataclass + `Step` enum + `ChunkingConfig` |
| `workflow/runner.py` | Executes each workflow step (FETCH, CLEAN, CHUNK, GROUP, PUSH…) |
| `workflow/cli.py` | Guided CLI for the full workflow |
| `workflow/suggest.py` | LLM suggests chunking params + generates collection metadata (topics, keywords, description, language, doc_type) |
| `web/app.py` | FastAPI web UI — Build RAG + Chat tabs |
| `run_app.py` | Launch web UI (opens browser at localhost:8000) |
| `solution_specs/solutions.yaml` | Single source of truth for all RAG solutions (collection name, type, scraper, aliases) |
| `solution_specs/loader.py` | Load/list/resolve solutions; designed to move to DB later |
| `ingestion/pdf_ingestion.py` | PDF text extraction via PyPDF2 |
| `ingestion/url_ingestion_legacy.py` | Archived Selenium crawlers (peixefresco, heyharper) — do not use for new work |
| `ingestion/scrapers/playwright_scraper.py` | Playwright engine — default for all sites (JS + SSR) |
| `ingestion/scrapers/httpx_scraper.py` | httpx+BS4 engine — fast option for confirmed SSR-only sites |
| `ingestion/scrapers/shopify_scraper.py` | Shopify JSON API engine — for Shopify stores |
| `ingestion/scrapers/runner.py` | Entry point for scrapers — loads YAML config, dispatches to correct engine |
| `ingestion/scrapers/configs/` | Per-site YAML scraper configs |
| `ingestion/scrapers/filters.py` | Named text filters applied in CLEAN step |
| `vectorization.py` | Chunking (LLM proposition) + embedding + point creation |
| `qdrant_utils.py` | Qdrant CRUD operations |
| `QdrantTracker.py` | High-level collection lifecycle manager |
| `chatbot.py` | Q&A pipeline: query rewriting → retrieval → LLM answer |
| `my_collections/` | Collection abstractions: `SCS_Collection`, `GroupCollection`, `groupCollection_sameSource` |
| `objects/` | `SCS`, `Group`, `Item` data objects |
| `grouping.py` | Semantic grouping of SCS chunks |

---

## Scraping Strategy — Key Decisions

Selenium has been replaced entirely. Three engines are available, selectable in the web UI and via YAML `engine:` field:

### Default: Playwright
For all sites. Handles JS-heavy pages, SPAs, Elementor, dynamic content. Smart waiting (networkidle). Use unless you know the site is purely SSR.

### httpx + BeautifulSoup4
For confirmed SSR-only sites (WordPress, WooCommerce without Elementor). ~10x faster than Playwright, no browser dependency.

### Shopify JSON API
For Shopify stores — use `/products.json?limit=250&page=N`. No HTML scraping needed.

### For HRIS/internal chatbots:
- API-first if the HRIS exposes one (BambooHR, Workday, etc.)
- PDF ingestion for policies/handbooks (`pdf_ingestion.py`)
- CSV export ingestion (`csv_ingestion.py`)

### Sitemap-driven scraping (preferred for WooCommerce/WordPress):
Sites with Yoast SEO expose clean sitemaps. Use `sitemap.xml` to get all URLs, then batch-fetch. Much simpler than crawling.

### Elementor sites (e.g. Peixe Fresco):
Standard CSS selectors often don't work — content lives in separate Elementor widget containers. Use `custom_js_extraction` in the YAML config: provide a JS function that runs in the browser and returns a fields dict. See `peixefresco_recipes.yaml` as reference.

---

## Peixe Fresco (store.peixefresco.com.pt) — Site Analysis

**Platform**: WordPress + WooCommerce + Yoast SEO

**Sitemaps available**:
| Sitemap | Count | Content |
|---------|-------|---------|
| `product-sitemap.xml` | 101 products | `/produto/` URLs |
| `receitas-sitemap.xml` | 11 recipes | `/receitas/` URLs |
| `page-sitemap.xml` | 23 pages | static pages |
| `product_cat-sitemap.xml` | — | product categories |
| `pa_finalidade-sitemap.xml` | — | attribute: cooking purpose |
| `pa_preparacao-sitemap.xml` | — | attribute: preparation type |

**Site uses Elementor** — standard WooCommerce CSS classes are overridden. Key selectors:
- Product name: `.product_title`
- Product price: `h2.elementor-heading-title:has(.woocommerce-Price-amount)`
- Attributes: WooCommerce table `th:has-text('Finalidade')` → sibling `td`
- Description: `.woocommerce-Tabs-panel--description`
- Recipe title: first `h2.elementor-heading-title` on page
- Recipe content: next Elementor widget after heading widget (use `custom_js_extraction`)
- Linked product URL: `a[href*='/produto/']` inside `.elementor-widget-wrap`

**RAG collections** (implemented, sitemap-driven Playwright):
1. `peixefresco_products` — 1 chunk per product via `product-sitemap.xml`
2. `peixefresco_recipes` — 1 chunk per recipe via `receitas-sitemap.xml` (custom JS extraction) + PDF `caderno_de_receitas_do_mar.pdf` (76pp, bilingual PT/ES → Translate & Clean → appended)
3. `peixefresco_pages` — static pages via `page-sitemap.xml` (httpx engine)

---

## Collection Routing Metadata

Each collection in `solutions.yaml` has a `routing` block used by the Session Engine for two-step collection selection:

**Step 1 — HIRS keyword match** (fast, free, deterministic):
- `routing.keywords`: matched against user input; high confidence → route directly, skip Step 2

**Step 2 — LLM semantic routing** (when HIRS is uncertain, ~$0.00007/call):
- Small prompt: description + typical_questions + not_covered for each candidate collection
- Returns JSON list of 1-3 collection ids to search

**Routing block fields** (auto-generated by `workflow/suggest.py → suggest_collection_metadata()`, manually editable in web UI):
- `description`: one sentence — what this collection contains
- `keywords`: 10-20 terms a user might search for
- `typical_questions`: 3-5 example questions this collection answers
- `not_covered`: topics/content types explicitly NOT here — helps LLM rule out collections
- `language`: ISO 639-1 code
- `doc_type`: `product_catalog | recipe_book | faq | manual | legal | general`

**Saving**: After chunking, routing metadata is auto-saved to `solutions.yaml` via `save_routing_metadata(solution_id, collection_id, metadata)`. The web UI shows the metadata with an Edit button for manual tuning.

**`solutions.yaml` is the contract** between this RAG builder and the Session Engine — the Session Engine reads routing metadata to build HIRS rules and the LLM routing prompt.

---

## State Persistence

- `WorkflowState` is the central object flowing through all pipeline steps
- Auto-saves to `.rag_state.json` at key steps (FETCH, TRANSLATE_AND_CLEAN, CHUNK)
- Can be resumed from saved state (web UI: "Load saved state")
- `solution_specs/solutions.yaml` is the registry of all collections

---

## Entry Points

```bash
python run_app.py          # Web UI at localhost:8000 (Build RAG + Chat)
python -m workflow.cli     # Guided CLI workflow
```

---

## Open Questions / Next Steps

- [x] Run Phase C: full Peixe Fresco product sitemap scrape → 96/101 chunks pushed to Qdrant
- [x] Run Phase D: recipes (11 web + PDF caderno de receitas) and pages collections — DONE
- [ ] Define API contract: how Session Engine calls this RAG layer (HTTP endpoint? direct Python import?)
- [ ] Future: integrate two-step routing in Session Engine using `solutions.yaml` routing metadata
- [ ] Future: migrate Hey Harper collections to new scraper (currently legacy Selenium data)

### Peixe Fresco — Collection Status (as of 2026-02-25)

| Collection | Source(s) | Status |
|---|---|---|
| `peixefresco_products` | Website sitemap (96/101 products) | ✅ Live in Qdrant |
| `peixefresco_recipes` | Website (11 recipes) + PDF caderno do mar (bilingual PT/ES, translated) | ✅ Live in Qdrant |
| `peixefresco_pages` | Static pages via httpx (about, FAQ, terms, legal) | ✅ Live in Qdrant |

**Multi-source collections**: `peixefresco_recipes` combines two sources in one Qdrant collection.
The append pattern (`QdrantTracker.append_points_to_collection()`) upserts new points without
wiping existing ones — used for Run 2 (PDF) after Run 1 (website scrape).

**LLM config for jBSE RAG responses**:
- Query rewriting: `gpt-4o-mini`
- Final answer generation: `gpt-4o`
- Qdrant URL: `https://94e2704d-31c5-4e24-b42a-e28f2554b078.eu-central-1-0.aws.cloud.qdrant.io`
- Embedding model: `text-embedding-ada-002` (OpenAI), 1536 dims, cosine similarity

---

## Conventions & Patterns

- **One solution = one or more Qdrant collections**, each with a `routing` block in `solution_specs/solutions.yaml`
- **Solution id maps 1:1** to a solution in the Jabberbrain Session Engine
- **Chunking default**: hierarchical (free, good quality). Use proposition only when quality matters and cost is acceptable.
- **New scrapers**: add a YAML in `ingestion/scrapers/configs/`, use Playwright (default) unless site is confirmed SSR.
- **Selenium**: archived as `url_ingestion_legacy.py`. Do not use for new work.
- **Elementor sites**: use `custom_js_extraction` in YAML — provide a JS function returning a fields dict.
- **Filters**: implement in `ingestion/scrapers/filters.py`, register by name, apply in CLEAN step.
- **LLM models**: GPT-4o-mini for processing steps, GPT-4o for final answers.
- **Versioning**: bump the `VERSION` file on meaningful changes. Major (`X.0.0`) for breaking/architectural changes. Minor (`0.X.0`) for new features or significant UI changes. Patch (`0.0.X`) for bug fixes, small tweaks, config changes. The version is displayed in the web UI header and exposed via `/api/version`.
