import time
from dotenv import load_dotenv
import os
import openai

# Load environment variables from .env file
load_dotenv()

_openaiclient = None

def get_openai_client():
    global _openaiclient
    if _openaiclient is None:  # Only initialize if not already created
        # to-do put this on the .env variable
        _openaiclient = openai.Client(api_key = os.getenv("OPENAI_API_KEY"))
    return _openaiclient

def clean_json_response(text):
    """Remove backticks and json tags from a GPT-typed json block."""
    text = text.strip()
    if text.startswith("```json"):
        text = text[len("```json"):].strip()
    if text.startswith("```"):
        text = text[len("```"):].strip()
    if text.endswith("```"):
        text = text[:-len("```")].strip()
    return text

def openai_chat_completion(prompt, text, model="gpt-4o-mini"):
    start_time = time.time()
    """
    Function to get a chat completion from OpenAI's API.
    
    Args:
        prompt (str): The system prompt for the chat model.
        text (str): The user input text for the chat model.
    
    Returns:
        content: Content of the response generated by the model.
    """
    openai_client = get_openai_client()
    
    # Example prompt and text
    # prompt = "You are a helpful assistant that generates sentences based on the provided text."
    # text = "Your input text goes here."
    try:
        #time.sleep(5) #temporary
        completion = openai_client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": prompt},
                    {"role": "user", "content": text}]
        )
    except openai.RateLimitError as e:
        # Extract details from the error object
        error_data = e.response.json()["error"]

        print(error_data)

        # Check if it's a token-per-minute (TPM) limit
        if "tokens per min" in error_data.get("message", "").lower():
            print("Hit the TPM (tokens per minute) limit. Will wait a bit and try again")
            time.sleep(10)  # Wait for 10 seconds before retrying
            completion = openai_client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": prompt},
                        {"role": "user", "content": text}]
            )
    #print(completion.choices[0].message.content)
    end_time = time.time()
    print(f"Elapsed time measured locally: {end_time - start_time:.2f} seconds")
    return completion.choices[0].message.content.strip()

# Helper: Wait for run to complete
def wait_for_run_completion(thread_id, run_id, poll_interval=0.1, timeout=100):
    start_time = time.time()
    while True:
        run = openai.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)
        if run.status == "completed":
            end_time = time.time()
            print(f"Elapsed time measured locally: {end_time - start_time:.2f} seconds")
            return run
        elif run.status in ["failed", "cancelled", "expired"]:
            raise Exception(f"Run failed with status: {run.status}")
        elif time.time() - start_time > timeout:
            raise TimeoutError("Run did not complete within timeout.")
        time.sleep(poll_interval)
        